{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**PROBLEM 1 – Reading the data in CoNLL format**"
      ],
      "metadata": {
        "id": "qRlI2QNWEH_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Define the URLs of the train and test data on GitHub\n",
        "train_url = 'https://raw.githubusercontent.com/spyysalo/ncbi-disease/master/conll/train.tsv'\n",
        "test_url = 'https://raw.githubusercontent.com/spyysalo/ncbi-disease/master/conll/test.tsv'\n",
        "\n",
        "# Download the train and test data from GitHub\n",
        "train_response = requests.get(train_url)\n",
        "test_response = requests.get(test_url)\n",
        "\n",
        "# Check if the downloads were successful\n",
        "if train_response.status_code == 200 and test_response.status_code == 200:\n",
        "    # Read the data from the response content\n",
        "    train_data = train_response.text\n",
        "    test_data = test_response.text\n",
        "\n",
        "    # Define the function to read CoNLL format\n",
        "    def read_conll_data(data):\n",
        "        token_sequences = []\n",
        "        tag_sequences = []\n",
        "        tokens = []\n",
        "        tags = []\n",
        "        for line in data.split('\\n'):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                if tokens and tags:\n",
        "                    token_sequences.append(tokens)\n",
        "                    tag_sequences.append(tags)\n",
        "                tokens = []\n",
        "                tags = []\n",
        "            else:\n",
        "                parts = line.split('\\t')\n",
        "                if len(parts) == 2:\n",
        "                    token, tag = parts\n",
        "                    tokens.append(token)\n",
        "                    tags.append(tag)\n",
        "        return token_sequences, tag_sequences\n",
        "\n",
        "    # Apply the function to the train and test data\n",
        "    train_tokens, train_tags = read_conll_data(train_data)\n",
        "    test_tokens, test_tags = read_conll_data(test_data)\n",
        "\n",
        "    # Show the requested information\n",
        "    print(f'Number of sequences in train: {len(train_tokens)}')\n",
        "    print(f'Number of sequences in test: {len(test_tokens)}')\n",
        "\n",
        "    print(\"Tokens and tags of the first sequence in the training dataset:\")\n",
        "    print(train_tokens[0])\n",
        "    print(train_tags[0])\n",
        "else:\n",
        "    print(\"Failed to download the data from GitHub. Please check the URLs.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMy9JaXKM9DH",
        "outputId": "7d639c30-662b-489e-ad45-d7f9e8bdad6e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sequences in train: 5432\n",
            "Number of sequences in test: 940\n",
            "Tokens and tags of the first sequence in the training dataset:\n",
            "['Identification', 'of', 'APC2', ',', 'a', 'homologue', 'of', 'the', 'adenomatous', 'polyposis', 'coli', 'tumour', 'suppressor', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Disease', 'I-Disease', 'I-Disease', 'I-Disease', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROBLEM 2 – Data Discovery**"
      ],
      "metadata": {
        "id": "ro_VgOEbEViu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Count the occurrences of each tag in the training data\n",
        "tag_counts = Counter(tag for tag_sequence in train_tags for tag in tag_sequence)\n",
        "\n",
        "# Count the 20 most common words/tokens associated with \"B-Disease\" and \"I-Disease\" tags\n",
        "disease_words_counter = Counter()\n",
        "for tokens, tags in zip(train_tokens, train_tags):\n",
        "    for token, tag in zip(tokens, tags):\n",
        "        if tag in [\"B-Disease\", \"I-Disease\"]:\n",
        "            disease_words_counter[token] += 1\n",
        "\n",
        "# Sort the disease words by frequency in descending order\n",
        "common_disease_words = disease_words_counter.most_common(20)\n",
        "\n",
        "# Print the tag counts\n",
        "print(\"Tag Counts in Training Data:\")\n",
        "print(tag_counts)\n",
        "\n",
        "# Print the count of the \"O\" tag\n",
        "print(f\"Count of 'O' tag: {tag_counts['O']}\")\n",
        "\n",
        "# Print the 20 most common disease-related words\n",
        "print(\"\\n20 Most Common Disease-Related Words:\")\n",
        "for word, count in common_disease_words:\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "# Optional: Print and read a small sample of token sequences\n",
        "sample_size = 5\n",
        "print(\"\\nSample of Token Sequences:\")\n",
        "for i in range(sample_size):\n",
        "    print(train_tokens[i])\n",
        "    print(train_tags[i])\n",
        "    print()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqSNqDNtPCOa",
        "outputId": "72af7cbd-b067-4bbe-a8be-7340bc287489"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag Counts in Training Data:\n",
            "Counter({'O': 124819, 'I-Disease': 6122, 'B-Disease': 5145})\n",
            "Count of 'O' tag: 124819\n",
            "\n",
            "20 Most Common Disease-Related Words:\n",
            "-: 636\n",
            "deficiency: 322\n",
            "syndrome: 281\n",
            "cancer: 269\n",
            "disease: 256\n",
            "of: 178\n",
            "dystrophy: 176\n",
            "breast: 151\n",
            "ovarian: 132\n",
            "X: 122\n",
            "and: 120\n",
            "DM: 120\n",
            "ALD: 114\n",
            "DMD: 110\n",
            "APC: 100\n",
            "disorder: 94\n",
            "muscular: 94\n",
            "G6PD: 92\n",
            "linked: 81\n",
            "the: 78\n",
            "\n",
            "Sample of Token Sequences:\n",
            "['Identification', 'of', 'APC2', ',', 'a', 'homologue', 'of', 'the', 'adenomatous', 'polyposis', 'coli', 'tumour', 'suppressor', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Disease', 'I-Disease', 'I-Disease', 'I-Disease', 'O', 'O']\n",
            "\n",
            "['The', 'adenomatous', 'polyposis', 'coli', '(', 'APC', ')', 'tumour', '-', 'suppressor', 'protein', 'controls', 'the', 'Wnt', 'signalling', 'pathway', 'by', 'forming', 'a', 'complex', 'with', 'glycogen', 'synthase', 'kinase', '3beta', '(', 'GSK', '-', '3beta', ')', ',', 'axin', '/', 'conductin', 'and', 'betacatenin', '.']\n",
            "['O', 'B-Disease', 'I-Disease', 'I-Disease', 'I-Disease', 'I-Disease', 'I-Disease', 'I-Disease', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "['Complex', 'formation', 'induces', 'the', 'rapid', 'degradation', 'of', 'betacatenin', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "['In', 'colon', 'carcinoma', 'cells', ',', 'loss', 'of', 'APC', 'leads', 'to', 'the', 'accumulation', 'of', 'betacatenin', 'in', 'the', 'nucleus', ',', 'where', 'it', 'binds', 'to', 'and', 'activates', 'the', 'Tcf', '-', '4', 'transcription', 'factor', '(', 'reviewed', 'in', '[', '1', ']', '[', '2', ']', ')', '.']\n",
            "['O', 'B-Disease', 'I-Disease', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "['Here', ',', 'we', 'report', 'the', 'identification', 'and', 'genomic', 'structure', 'of', 'APC', 'homologues', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***PROBLEM 3 – Building features ***"
      ],
      "metadata": {
        "id": "EhN2BGGzEftF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_crf_features(tokens, position):\n",
        "    features = []\n",
        "\n",
        "    # Get the current word/token in lowercase\n",
        "    current_word = tokens[position].lower()\n",
        "    features.append(\"word=\" + current_word)\n",
        "\n",
        "    # Get the suffix (last 3 characters) of the current word\n",
        "    suffix = current_word[-3:]\n",
        "    features.append(\"suffix=\" + suffix)\n",
        "\n",
        "    # Get the previous word/token or \"BOS\" if at the beginning of the sequence\n",
        "    if position > 0:\n",
        "        previous_word = tokens[position - 1].lower()\n",
        "    else:\n",
        "        previous_word = \"BOS\"\n",
        "    features.append(\"prev_word=\" + previous_word)\n",
        "\n",
        "    # Get the next word/token or \"EOS\" if at the end of the sequence\n",
        "    if position < len(tokens) - 1:\n",
        "        next_word = tokens[position + 1].lower()\n",
        "    else:\n",
        "        next_word = \"EOS\"\n",
        "    features.append(\"next_word=\" + next_word)\n",
        "\n",
        "    # Add at least one other feature of your choice\n",
        "    # For example, you can add the length of the current word\n",
        "    word_length = len(current_word)\n",
        "    features.append(\"word_length=\" + str(word_length))\n",
        "\n",
        "    return features\n",
        "# Assuming train_tokens and test_tokens are your sequences of tokens\n",
        "train_features = []\n",
        "test_features = []\n",
        "\n",
        "# Generate features for the training set\n",
        "for i in range(len(train_tokens[0])):\n",
        "    features = generate_crf_features(train_tokens[0], i)\n",
        "    train_features.append(features)\n",
        "\n",
        "# Generate features for the test set\n",
        "for i in range(len(test_tokens[0])):\n",
        "    features = generate_crf_features(test_tokens[0], i)\n",
        "    test_features.append(features)\n",
        "for i in range(3):\n",
        "    features = generate_crf_features(train_tokens[0], i)\n",
        "    print(f\"Features for word {i + 1}: {features}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2wxJLK-PuYP",
        "outputId": "0a1b26b3-6fb0-48b3-b05d-a18de517ff2e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features for word 1: ['word=identification', 'suffix=ion', 'prev_word=BOS', 'next_word=of', 'word_length=14']\n",
            "Features for word 2: ['word=of', 'suffix=of', 'prev_word=identification', 'next_word=apc2', 'word_length=2']\n",
            "Features for word 3: ['word=apc2', 'suffix=pc2', 'prev_word=of', 'next_word=,', 'word_length=4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sklearn-crfsuite\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doMUjLbum8by",
        "outputId": "21a4e2d3-caae-409d-94a4-411a74b4d54e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.10/dist-packages (0.3.6)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (0.9.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROBLEM 4 – Training a CRF model**"
      ],
      "metadata": {
        "id": "4syOPQPaEulk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pycrfsuite\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define the function to generate CRF features\n",
        "def generate_crf_features(tokens, position):\n",
        "    features = []\n",
        "\n",
        "    # Get the current word/token in lowercase\n",
        "    current_word = tokens[position].lower()\n",
        "    features.append(\"word=\" + current_word)\n",
        "\n",
        "    # Get the suffix (last 3 characters) of the current word\n",
        "    suffix = current_word[-3:]\n",
        "    features.append(\"suffix=\" + suffix)\n",
        "\n",
        "    # Get the previous word/token or \"BOS\" if at the beginning of the sequence\n",
        "    if position > 0:\n",
        "        previous_word = tokens[position - 1].lower()\n",
        "    else:\n",
        "        previous_word = \"BOS\"\n",
        "    features.append(\"prev_word=\" + previous_word)\n",
        "\n",
        "    # Get the next word/token or \"EOS\" if at the end of the sequence\n",
        "    if position < len(tokens) - 1:\n",
        "        next_word = tokens[position + 1].lower()\n",
        "    else:\n",
        "        next_word = \"EOS\"\n",
        "    features.append(\"next_word=\" + next_word)\n",
        "\n",
        "    # Add at least one other feature of your choice\n",
        "    # For example, you can add the length of the current word\n",
        "    word_length = len(current_word)\n",
        "    features.append(\"word_length=\" + str(word_length))\n",
        "\n",
        "    return features\n",
        "\n",
        "# Prepare training and test data\n",
        "train_data = []  # Training data in the required format\n",
        "\n",
        "for i in range(len(train_tokens)):\n",
        "    sequence = []\n",
        "    for j in range(len(train_tokens[i])):\n",
        "        features = generate_crf_features(train_tokens[i], j)\n",
        "        label = train_tags[i][j]\n",
        "        sequence.append((features, label))\n",
        "    train_data.append(sequence)\n",
        "\n",
        "test_data = []  # Test data in the required format\n",
        "\n",
        "for i in range(len(test_tokens)):\n",
        "    sequence = []\n",
        "    for j in range(len(test_tokens[i])):\n",
        "        features = generate_crf_features(test_tokens[i], j)\n",
        "        label = test_tags[i][j]\n",
        "        sequence.append((features, label))\n",
        "    test_data.append(sequence)\n",
        "\n",
        "# Train a CRF model\n",
        "trainer = pycrfsuite.Trainer(verbose=True)\n",
        "\n",
        "for sequence in train_data:\n",
        "    features, labels = zip(*sequence)\n",
        "    trainer.append(features, labels)\n",
        "\n",
        "trainer.set_params({\n",
        "    'c1': 1.0,   # Coefficient for L1 penalty\n",
        "    'c2': 1e-3,  # Coefficient for L2 penalty\n",
        "    'max_iterations': 50,  # Maximum number of iterations\n",
        "    'feature.possible_transitions': True  # Include transitions that are possible but not observed in the training data\n",
        "})\n",
        "\n",
        "model_filename = 'disease_ner_model.crfsuite'\n",
        "trainer.train(model_filename)\n",
        "\n",
        "# Apply the trained model to the test data\n",
        "tagger = pycrfsuite.Tagger()\n",
        "tagger.open(model_filename)\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "for sequence in test_data:\n",
        "    features, labels = zip(*sequence)\n",
        "    true_labels.extend(labels)\n",
        "    predicted_labels.extend(tagger.tag(features))\n",
        "\n",
        "# Compute precision, recall, and f1-score\n",
        "report = classification_report(true_labels, predicted_labels, target_names=[\"B-Disease\", \"I-Disease\", \"O\"])\n",
        "print(report)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggtjCJ97mPYe",
        "outputId": "37cea39d-8854-47bb-c216-0ace77c21470"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 1\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 31427\n",
            "Seconds required: 0.163\n",
            "\n",
            "L-BFGS optimization\n",
            "c1: 1.000000\n",
            "c2: 0.001000\n",
            "num_memories: 6\n",
            "max_iterations: 50\n",
            "epsilon: 0.000010\n",
            "stop: 10\n",
            "delta: 0.000010\n",
            "linesearch: MoreThuente\n",
            "linesearch.max_iterations: 20\n",
            "\n",
            "***** Iteration #1 *****\n",
            "Loss: 59226.712924\n",
            "Feature norm: 1.000000\n",
            "Error norm: 56235.351331\n",
            "Active features: 19269\n",
            "Line search trials: 1\n",
            "Line search step: 0.000009\n",
            "Seconds required for this iteration: 0.085\n",
            "\n",
            "***** Iteration #2 *****\n",
            "Loss: 39479.990407\n",
            "Feature norm: 2.024324\n",
            "Error norm: 9302.959581\n",
            "Active features: 14464\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.043\n",
            "\n",
            "***** Iteration #3 *****\n",
            "Loss: 38396.629957\n",
            "Feature norm: 1.941927\n",
            "Error norm: 7655.557917\n",
            "Active features: 13594\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.045\n",
            "\n",
            "***** Iteration #4 *****\n",
            "Loss: 36271.921662\n",
            "Feature norm: 1.802545\n",
            "Error norm: 11674.868882\n",
            "Active features: 8629\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.044\n",
            "\n",
            "***** Iteration #5 *****\n",
            "Loss: 34667.586838\n",
            "Feature norm: 1.956330\n",
            "Error norm: 7807.653509\n",
            "Active features: 8836\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.048\n",
            "\n",
            "***** Iteration #6 *****\n",
            "Loss: 27138.577941\n",
            "Feature norm: 3.351998\n",
            "Error norm: 3847.317780\n",
            "Active features: 8338\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.045\n",
            "\n",
            "***** Iteration #7 *****\n",
            "Loss: 24984.489735\n",
            "Feature norm: 5.468897\n",
            "Error norm: 20177.482024\n",
            "Active features: 8323\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.045\n",
            "\n",
            "***** Iteration #8 *****\n",
            "Loss: 22624.310453\n",
            "Feature norm: 5.345337\n",
            "Error norm: 2414.543031\n",
            "Active features: 10431\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.049\n",
            "\n",
            "***** Iteration #9 *****\n",
            "Loss: 21823.105674\n",
            "Feature norm: 5.815626\n",
            "Error norm: 2223.433073\n",
            "Active features: 10118\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.049\n",
            "\n",
            "***** Iteration #10 *****\n",
            "Loss: 17600.585190\n",
            "Feature norm: 9.482290\n",
            "Error norm: 1949.209697\n",
            "Active features: 8026\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.047\n",
            "\n",
            "***** Iteration #11 *****\n",
            "Loss: 15731.747161\n",
            "Feature norm: 11.905398\n",
            "Error norm: 1299.464628\n",
            "Active features: 7615\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.056\n",
            "\n",
            "***** Iteration #12 *****\n",
            "Loss: 14499.528014\n",
            "Feature norm: 15.312423\n",
            "Error norm: 5793.421426\n",
            "Active features: 7527\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.044\n",
            "\n",
            "***** Iteration #13 *****\n",
            "Loss: 13311.937471\n",
            "Feature norm: 17.062378\n",
            "Error norm: 1253.045264\n",
            "Active features: 7701\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.044\n",
            "\n",
            "***** Iteration #14 *****\n",
            "Loss: 12363.903649\n",
            "Feature norm: 18.895814\n",
            "Error norm: 630.601850\n",
            "Active features: 7648\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.046\n",
            "\n",
            "***** Iteration #15 *****\n",
            "Loss: 11212.586187\n",
            "Feature norm: 23.490067\n",
            "Error norm: 3977.424654\n",
            "Active features: 7398\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.044\n",
            "\n",
            "***** Iteration #16 *****\n",
            "Loss: 10531.453797\n",
            "Feature norm: 24.377476\n",
            "Error norm: 555.209515\n",
            "Active features: 7461\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.047\n",
            "\n",
            "***** Iteration #17 *****\n",
            "Loss: 9935.461805\n",
            "Feature norm: 26.198066\n",
            "Error norm: 859.751667\n",
            "Active features: 7333\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.045\n",
            "\n",
            "***** Iteration #18 *****\n",
            "Loss: 9123.855360\n",
            "Feature norm: 30.790213\n",
            "Error norm: 1226.315899\n",
            "Active features: 6954\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.044\n",
            "\n",
            "***** Iteration #19 *****\n",
            "Loss: 8740.716960\n",
            "Feature norm: 32.062328\n",
            "Error norm: 363.519927\n",
            "Active features: 6859\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.048\n",
            "\n",
            "***** Iteration #20 *****\n",
            "Loss: 8292.584135\n",
            "Feature norm: 34.881702\n",
            "Error norm: 260.309882\n",
            "Active features: 6584\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.045\n",
            "\n",
            "***** Iteration #21 *****\n",
            "Loss: 8172.868332\n",
            "Feature norm: 37.611297\n",
            "Error norm: 2054.168151\n",
            "Active features: 6304\n",
            "Line search trials: 2\n",
            "Line search step: 0.500000\n",
            "Seconds required for this iteration: 0.092\n",
            "\n",
            "***** Iteration #22 *****\n",
            "Loss: 7827.639796\n",
            "Feature norm: 39.878563\n",
            "Error norm: 585.494904\n",
            "Active features: 6297\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.048\n",
            "\n",
            "***** Iteration #23 *****\n",
            "Loss: 7654.638926\n",
            "Feature norm: 40.901295\n",
            "Error norm: 294.395326\n",
            "Active features: 6232\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.045\n",
            "\n",
            "***** Iteration #24 *****\n",
            "Loss: 7327.578197\n",
            "Feature norm: 44.353980\n",
            "Error norm: 214.441138\n",
            "Active features: 5934\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.046\n",
            "\n",
            "***** Iteration #25 *****\n",
            "Loss: 7192.734842\n",
            "Feature norm: 46.775145\n",
            "Error norm: 1403.677850\n",
            "Active features: 5614\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.047\n",
            "\n",
            "***** Iteration #26 *****\n",
            "Loss: 7003.038965\n",
            "Feature norm: 47.524513\n",
            "Error norm: 345.095265\n",
            "Active features: 5586\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.044\n",
            "\n",
            "***** Iteration #27 *****\n",
            "Loss: 6904.923904\n",
            "Feature norm: 48.657347\n",
            "Error norm: 156.284105\n",
            "Active features: 5445\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.044\n",
            "\n",
            "***** Iteration #28 *****\n",
            "Loss: 6726.880290\n",
            "Feature norm: 51.280291\n",
            "Error norm: 149.812060\n",
            "Active features: 5168\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.045\n",
            "\n",
            "***** Iteration #29 *****\n",
            "Loss: 6654.162147\n",
            "Feature norm: 53.756708\n",
            "Error norm: 1377.038352\n",
            "Active features: 4863\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.048\n",
            "\n",
            "***** Iteration #30 *****\n",
            "Loss: 6547.273797\n",
            "Feature norm: 54.917733\n",
            "Error norm: 1001.150086\n",
            "Active features: 4825\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.045\n",
            "\n",
            "***** Iteration #31 *****\n",
            "Loss: 6493.271131\n",
            "Feature norm: 55.766705\n",
            "Error norm: 262.896724\n",
            "Active features: 4786\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.044\n",
            "\n",
            "***** Iteration #32 *****\n",
            "Loss: 6452.415966\n",
            "Feature norm: 56.587156\n",
            "Error norm: 169.594492\n",
            "Active features: 4663\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.051\n",
            "\n",
            "***** Iteration #33 *****\n",
            "Loss: 6361.825476\n",
            "Feature norm: 58.715703\n",
            "Error norm: 250.538111\n",
            "Active features: 4435\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.044\n",
            "\n",
            "***** Iteration #34 *****\n",
            "Loss: 6316.237523\n",
            "Feature norm: 61.071724\n",
            "Error norm: 919.076213\n",
            "Active features: 4136\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.047\n",
            "\n",
            "***** Iteration #35 *****\n",
            "Loss: 6264.805723\n",
            "Feature norm: 61.708564\n",
            "Error norm: 181.650492\n",
            "Active features: 4141\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.049\n",
            "\n",
            "***** Iteration #36 *****\n",
            "Loss: 6240.736313\n",
            "Feature norm: 62.286273\n",
            "Error norm: 210.445384\n",
            "Active features: 4068\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.044\n",
            "\n",
            "***** Iteration #37 *****\n",
            "Loss: 6203.511999\n",
            "Feature norm: 63.105821\n",
            "Error norm: 121.210773\n",
            "Active features: 4003\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.046\n",
            "\n",
            "***** Iteration #38 *****\n",
            "Loss: 6165.453102\n",
            "Feature norm: 63.927945\n",
            "Error norm: 262.880050\n",
            "Active features: 3901\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.045\n",
            "\n",
            "***** Iteration #39 *****\n",
            "Loss: 6138.381796\n",
            "Feature norm: 64.454967\n",
            "Error norm: 142.484540\n",
            "Active features: 3799\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.044\n",
            "\n",
            "***** Iteration #40 *****\n",
            "Loss: 6110.924735\n",
            "Feature norm: 65.288275\n",
            "Error norm: 142.471422\n",
            "Active features: 3739\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.045\n",
            "\n",
            "***** Iteration #41 *****\n",
            "Loss: 6085.957389\n",
            "Feature norm: 65.923261\n",
            "Error norm: 173.794549\n",
            "Active features: 3659\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.044\n",
            "\n",
            "***** Iteration #42 *****\n",
            "Loss: 6068.208241\n",
            "Feature norm: 66.825442\n",
            "Error norm: 167.425269\n",
            "Active features: 3590\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.048\n",
            "\n",
            "***** Iteration #43 *****\n",
            "Loss: 6053.311506\n",
            "Feature norm: 67.088357\n",
            "Error norm: 71.946288\n",
            "Active features: 3510\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.046\n",
            "\n",
            "***** Iteration #44 *****\n",
            "Loss: 6032.066848\n",
            "Feature norm: 68.133834\n",
            "Error norm: 200.575638\n",
            "Active features: 3337\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.044\n",
            "\n",
            "***** Iteration #45 *****\n",
            "Loss: 6021.849572\n",
            "Feature norm: 68.481413\n",
            "Error norm: 116.162714\n",
            "Active features: 3297\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.043\n",
            "\n",
            "***** Iteration #46 *****\n",
            "Loss: 6011.995768\n",
            "Feature norm: 69.056899\n",
            "Error norm: 132.292022\n",
            "Active features: 3246\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.047\n",
            "\n",
            "***** Iteration #47 *****\n",
            "Loss: 6002.229634\n",
            "Feature norm: 69.473446\n",
            "Error norm: 120.006403\n",
            "Active features: 3220\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.044\n",
            "\n",
            "***** Iteration #48 *****\n",
            "Loss: 5993.886385\n",
            "Feature norm: 70.002899\n",
            "Error norm: 171.255091\n",
            "Active features: 3173\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.043\n",
            "\n",
            "***** Iteration #49 *****\n",
            "Loss: 5986.723460\n",
            "Feature norm: 70.268821\n",
            "Error norm: 162.145716\n",
            "Active features: 3129\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.044\n",
            "\n",
            "***** Iteration #50 *****\n",
            "Loss: 5979.140622\n",
            "Feature norm: 70.797813\n",
            "Error norm: 144.976701\n",
            "Active features: 3102\n",
            "Line search trials: 1\n",
            "Line search step: 1.000000\n",
            "Seconds required for this iteration: 0.048\n",
            "\n",
            "L-BFGS terminated with the maximum number of iterations\n",
            "Total seconds required for training: 2.380\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 3102 (31427)\n",
            "Number of active attributes: 2139 (27706)\n",
            "Number of active labels: 3 (3)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.003\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   B-Disease       0.86      0.70      0.77       960\n",
            "   I-Disease       0.84      0.74      0.79      1087\n",
            "           O       0.98      0.99      0.98     22450\n",
            "\n",
            "    accuracy                           0.97     24497\n",
            "   macro avg       0.89      0.81      0.85     24497\n",
            "weighted avg       0.97      0.97      0.97     24497\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROBLEM 5 – Inspecting the trained model **"
      ],
      "metadata": {
        "id": "TV_cttupE2y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show parameter weights for transitions between tag types\n",
        "transition_weights = tagger.info().transitions\n",
        "print(\"Parameter weights for transitions between tag types:\")\n",
        "for label_from, label_to in transition_weights:\n",
        "    weight = transition_weights[(label_from, label_to)]\n",
        "    print(f\"Transition: {label_from} -> {label_to}, Weight: {weight}\")\n",
        "\n",
        "# Show parameter weights for the \"word_length\" feature\n",
        "state_features = tagger.info().state_features\n",
        "word_length_weights = {feature: weight for feature, weight in state_features.items() if \"word_length\" in feature}\n",
        "print(\"\\nParameter weights for the 'word_length' feature:\")\n",
        "for feature, weight in word_length_weights.items():\n",
        "    print(f\"Feature: {feature}, Weight: {weight}\")\n",
        "\n",
        "# Corrected feature name\n",
        "my_feature_name = 'word_length'  # Feature\n",
        "\n",
        "# Display parameter weights for the specified feature\n",
        "feature_weights = tagger.info().state_features\n",
        "print(f\"Parameter weights for feature '{my_feature_name}':\")\n",
        "for feature, weight in feature_weights.items():\n",
        "    feature_str = ' '.join(feature)  # Convert the feature tuple to a string\n",
        "    if feature_str.startswith(my_feature_name):\n",
        "        print(f\"{feature_str}: {weight}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wQYNRvlVnYk",
        "outputId": "92c9825c-5de2-4fdf-828f-ba5d75f78ab2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter weights for transitions between tag types:\n",
            "Transition: O -> O, Weight: 1.952336\n",
            "Transition: O -> B-Disease, Weight: -0.455422\n",
            "Transition: O -> I-Disease, Weight: -8.443748\n",
            "Transition: B-Disease -> O, Weight: -1.592283\n",
            "Transition: B-Disease -> B-Disease, Weight: -5.688209\n",
            "Transition: B-Disease -> I-Disease, Weight: 1.937948\n",
            "Transition: I-Disease -> O, Weight: -1.72059\n",
            "Transition: I-Disease -> B-Disease, Weight: -4.353711\n",
            "Transition: I-Disease -> I-Disease, Weight: 1.911456\n",
            "\n",
            "Parameter weights for the 'word_length' feature:\n",
            "Parameter weights for feature 'word_length':\n",
            "word_length=14 O: -0.075894\n",
            "word_length=14 B-Disease: 0.156378\n",
            "word_length=2 O: 0.829588\n",
            "word_length=2 B-Disease: -0.771092\n",
            "word_length=2 I-Disease: -0.721985\n",
            "word_length=4 O: 0.820452\n",
            "word_length=4 B-Disease: -0.345401\n",
            "word_length=4 I-Disease: -0.477079\n",
            "word_length=1 O: 1.774242\n",
            "word_length=1 B-Disease: -2.535428\n",
            "word_length=1 I-Disease: 0.000515\n",
            "word_length=9 O: 0.075153\n",
            "word_length=9 B-Disease: -0.076107\n",
            "word_length=9 I-Disease: -0.177396\n",
            "word_length=3 O: 0.1825\n",
            "word_length=3 B-Disease: -0.010764\n",
            "word_length=3 I-Disease: -0.718703\n",
            "word_length=11 O: 0.103558\n",
            "word_length=11 B-Disease: -0.240302\n",
            "word_length=11 I-Disease: -0.058577\n",
            "word_length=6 O: 0.261589\n",
            "word_length=6 B-Disease: -0.467804\n",
            "word_length=6 I-Disease: -0.260238\n",
            "word_length=10 O: 0.20253\n",
            "word_length=10 B-Disease: -0.068965\n",
            "word_length=10 I-Disease: -0.265982\n",
            "word_length=7 O: 0.485039\n",
            "word_length=7 B-Disease: -0.245902\n",
            "word_length=7 I-Disease: -0.099405\n",
            "word_length=8 O: 0.548168\n",
            "word_length=8 B-Disease: 0.023715\n",
            "word_length=8 I-Disease: -0.097213\n",
            "word_length=5 O: 0.781591\n",
            "word_length=5 B-Disease: -0.40354\n",
            "word_length=5 I-Disease: 0.004052\n",
            "word_length=12 O: 0.243878\n",
            "word_length=13 O: 0.014378\n",
            "word_length=13 B-Disease: 0.163965\n",
            "word_length=13 I-Disease: -0.145113\n",
            "word_length=15 O: -0.557724\n",
            "word_length=15 B-Disease: 0.606896\n",
            "word_length=15 I-Disease: -0.046079\n",
            "word_length=16 O: -0.992215\n",
            "word_length=16 B-Disease: 0.604835\n",
            "word_length=17 O: -0.276114\n",
            "word_length=17 B-Disease: 0.975245\n",
            "word_length=18 O: -0.664527\n",
            "word_length=18 B-Disease: 0.27587\n",
            "word_length=21 O: -0.986072\n",
            "word_length=21 B-Disease: 1.388699\n",
            "word_length=20 O: -0.704296\n",
            "word_length=20 B-Disease: 1.342791\n",
            "word_length=19 I-Disease: 0.19088\n",
            "word_length=22 B-Disease: 1.691744\n",
            "word_length=23 I-Disease: 0.272116\n",
            "word_length=25 O: -0.616526\n",
            "word_length=25 B-Disease: 0.747056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROBLEM 6 – Document level performance**"
      ],
      "metadata": {
        "id": "L9TwKMsmE_HM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def aggregate_labels(tag_sequence):\n",
        "    # Check if the tag sequence contains at least one \"B-Disease\" tag\n",
        "    return 1 if \"B-Disease\" in tag_sequence else 0\n",
        "\n",
        "# Apply the aggregation function to the true and predicted test labels\n",
        "true_document_labels = [aggregate_labels(tag_sequence) for tag_sequence in test_tags]\n",
        "predicted_document_labels = [aggregate_labels(tag_sequence) for tag_sequence in y_pred]\n",
        "\n",
        "# Calculate document-level precision and recall\n",
        "true_positive = sum(1 for true_label, predicted_label in zip(true_document_labels, predicted_document_labels) if true_label == 1 and predicted_label == 1)\n",
        "false_positive = sum(1 for true_label, predicted_label in zip(true_document_labels, predicted_document_labels) if true_label == 0 and predicted_label == 1)\n",
        "false_negative = sum(1 for true_label, predicted_label in zip(true_document_labels, predicted_document_labels) if true_label == 1 and predicted_label == 0)\n",
        "\n",
        "document_precision = true_positive / (true_positive + false_positive)\n",
        "document_recall = true_positive / (true_positive + false_negative)\n",
        "\n",
        "# Print document-level precision and recall\n",
        "print(f\"Document-level Precision: {document_precision:.2f}\")\n",
        "print(f\"Document-level Recall: {document_recall:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDlcIBwtXInQ",
        "outputId": "a9c8e339-6020-48b3-9e6d-1ab0a32a26e5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document-level Precision: 1.00\n",
            "Document-level Recall: 1.00\n"
          ]
        }
      ]
    }
  ]
}